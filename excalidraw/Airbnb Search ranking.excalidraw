{"type":"excalidraw","version":2,"source":"https://app.excalidraw.com","metadata":{"id":"4KOyeO81gG6","workspace":"6lsqOkFWqjK","name":"Airbnb Search ranking","created":"2025-10-29T18:23:22.723Z","updated":"2025-10-29T21:28:36.379Z","collection":null,"creator":"Alx6QpYT9Vj","updater":"Alx6QpYT9Vj","isPrivate":true,"pinned":false},"elements":[{"id":"tBSzeTJPTJdV_fTwTHTLk","type":"text","x":291,"y":400.8828125,"width":1516.73876953125,"height":2900,"angle":0,"strokeColor":"#1e1e1e","backgroundColor":"transparent","fillStyle":"solid","strokeWidth":2,"strokeStyle":"solid","roughness":1,"opacity":100,"groupIds":[],"frameId":null,"index":"a0","roundness":null,"seed":215570332,"version":4454,"versionNonce":313495068,"isDeleted":false,"boundElements":null,"updated":1761773312162,"link":null,"locked":false,"text":"Design heavy ranker for Airbnb search\n\nCQ:\n- surfaces: home search? experiences? mixed? multi lingual?\n- latency budget: 80ms (total 150 ms)\n- candidate size from retrival? EBR? (800-1500)?\n- primary KPI: booking lift (per session, per impression)\n-- secondary: high quality engagement, wishlist, long view, share\n- faurdrail: complaint/report rate, bounce after clic, diversity,\n- filters must be obeyed before\n- cold start?\n- caliberation per region?\n\n\n\nHigh level:\n- objective proba (book|user, listing, context) and auxliary heads fro wishlist, click, long view\n- 3 stage: retrival (ER), heavy ranker, reranker (freshness, diversity, fairness)\n- multi task learning (MMOE) to avoid negative transfer between sparse (booking) and dense (cick),\n- allow focal loss\n- DCN V2 for deep feature crosses, user sequence encoder for recency\n\n\n\nData contruction:\n- user:\n-- user id, demographic (bucketized), cluster of interestes, historical (spend, price band, prior destination, seasonality, seq embedding of last n inteactions)\n\n- listing:\n-- listing id, location cell (lat, long bucketized), amenitiges (onehot), tage (BOW), description (BERT), availablity score\n-- quality review signal, host id, host features (rating, response latency, cancel rate),\n-- image embeddings pre computed using sinclr or clip offline)=> or can be done online co-trained (or offline cotrained)\n\n\n- request / context:\n-- langauge, device, geo, holoday, lead time, los, fulter set, DOW, TOD\n\n- cross features:\n-- user X listing: price aligmnemtn, amenity overlap, distance to interst, prior host gues affinity\n\n- feature store:\n-- static vs dynamic with ttl, on eht fly caching, strict train serve parity\n\n\n\n\nModeling architecture:\n- core:\n-- single tower DNN over concatenated dense + embedding features\n-- DCN V2 for efficient high order crosses, MMOE trunk, heads (book, wishlist, click, long view)\n-- loss weighted sum of BCE oer head\n-- focal loss on rare heads (booking to emphasize important hard examples)\n\n- sequence:\n-- lightweight transformer over recent user actions, user seq embedding fed into trunk\n\n- calibeartion:\n-- per region plat scaling on valiudation buckets, becessary for threshold actions and fair exposure\n\n- output serving rank score: wb pbook, ww pwishlist,wc pckclc (tuned offline to offline mapping)\n\n\nTraining:\n- Negative down sampling, class weights for focal on sparse head, gradient blednding to balance tasks\n- regularization: drop out L2, eary stopping, label smoothing\n- distilation path: train a light ranker\n\n\nContinual learning\n- daily refresh, drif triggered trains, safe gards, catastrphic for getting, \n\n\nEval offline:\n- NDCG on compositve relevance\n- per head AUC, PRU-AUC for calibeation\n- diversity metric: mean pairwise consine distance among top k embedding\n\n- online:\n-- booking rate, wishlist, rate, dau, session revenue\n-- guardrail: complaint rate, dislike report, churn, latency budget\n\n\nServiong:\n-- inpiut top k from ber with hard filter applied\n-- feature hydration: cache hot features, user profile, listing static, precompute image/text embedding, stream dynamics\n-- budget split suggestion (30,70,30)\n-- effcieincy: pruning, quantization, embedding size optimization, prediction caching for repeated views\n\n Reranker:\n-- freshnes boost for new listing,\n-- diversity penalty on near duplicate (cosine sim threshold from prev)\n-- popularity penality\n-- enforce exposure fairness by host\n\nDeployment\n- shadow, vs current ranker => prediction distribution sanity\n- canary: 1-5% traffic, with auto rollback on gardrails \n- optional multi arm bandit\n\n\nMonitoring:\n-- Quality NDCG drif, per head PR AUC, caliberati drif\n- business boolking lif, session revenue, dau, gaurdrails\n\nCold start:\n- listing: leverage context\n- user: cluster priors + short onboarding quizes\n- drop out id features during training to avoid over memorization\n\nIntegration:\n- path EBR similarity as a feature to ranker\n- maintain recal targets from retrival so ranker otpimizes precision\n\n\n\n","fontSize":20,"fontFamily":5,"textAlign":"left","verticalAlign":"top","containerId":null,"originalText":"Design heavy ranker for Airbnb search\n\nCQ:\n- surfaces: home search? experiences? mixed? multi lingual?\n- latency budget: 80ms (total 150 ms)\n- candidate size from retrival? EBR? (800-1500)?\n- primary KPI: booking lift (per session, per impression)\n-- secondary: high quality engagement, wishlist, long view, share\n- faurdrail: complaint/report rate, bounce after clic, diversity,\n- filters must be obeyed before\n- cold start?\n- caliberation per region?\n\n\n\nHigh level:\n- objective proba (book|user, listing, context) and auxliary heads fro wishlist, click, long view\n- 3 stage: retrival (ER), heavy ranker, reranker (freshness, diversity, fairness)\n- multi task learning (MMOE) to avoid negative transfer between sparse (booking) and dense (cick),\n- allow focal loss\n- DCN V2 for deep feature crosses, user sequence encoder for recency\n\n\n\nData contruction:\n- user:\n-- user id, demographic (bucketized), cluster of interestes, historical (spend, price band, prior destination, seasonality, seq embedding of last n inteactions)\n\n- listing:\n-- listing id, location cell (lat, long bucketized), amenitiges (onehot), tage (BOW), description (BERT), availablity score\n-- quality review signal, host id, host features (rating, response latency, cancel rate),\n-- image embeddings pre computed using sinclr or clip offline)=> or can be done online co-trained (or offline cotrained)\n\n\n- request / context:\n-- langauge, device, geo, holoday, lead time, los, fulter set, DOW, TOD\n\n- cross features:\n-- user X listing: price aligmnemtn, amenity overlap, distance to interst, prior host gues affinity\n\n- feature store:\n-- static vs dynamic with ttl, on eht fly caching, strict train serve parity\n\n\n\n\nModeling architecture:\n- core:\n-- single tower DNN over concatenated dense + embedding features\n-- DCN V2 for efficient high order crosses, MMOE trunk, heads (book, wishlist, click, long view)\n-- loss weighted sum of BCE oer head\n-- focal loss on rare heads (booking to emphasize important hard examples)\n\n- sequence:\n-- lightweight transformer over recent user actions, user seq embedding fed into trunk\n\n- calibeartion:\n-- per region plat scaling on valiudation buckets, becessary for threshold actions and fair exposure\n\n- output serving rank score: wb pbook, ww pwishlist,wc pckclc (tuned offline to offline mapping)\n\n\nTraining:\n- Negative down sampling, class weights for focal on sparse head, gradient blednding to balance tasks\n- regularization: drop out L2, eary stopping, label smoothing\n- distilation path: train a light ranker\n\n\nContinual learning\n- daily refresh, drif triggered trains, safe gards, catastrphic for getting, \n\n\nEval offline:\n- NDCG on compositve relevance\n- per head AUC, PRU-AUC for calibeation\n- diversity metric: mean pairwise consine distance among top k embedding\n\n- online:\n-- booking rate, wishlist, rate, dau, session revenue\n-- guardrail: complaint rate, dislike report, churn, latency budget\n\n\nServiong:\n-- inpiut top k from ber with hard filter applied\n-- feature hydration: cache hot features, user profile, listing static, precompute image/text embedding, stream dynamics\n-- budget split suggestion (30,70,30)\n-- effcieincy: pruning, quantization, embedding size optimization, prediction caching for repeated views\n\n Reranker:\n-- freshnes boost for new listing,\n-- diversity penalty on near duplicate (cosine sim threshold from prev)\n-- popularity penality\n-- enforce exposure fairness by host\n\nDeployment\n- shadow, vs current ranker => prediction distribution sanity\n- canary: 1-5% traffic, with auto rollback on gardrails \n- optional multi arm bandit\n\n\nMonitoring:\n-- Quality NDCG drif, per head PR AUC, caliberati drif\n- business boolking lif, session revenue, dau, gaurdrails\n\nCold start:\n- listing: leverage context\n- user: cluster priors + short onboarding quizes\n- drop out id features during training to avoid over memorization\n\nIntegration:\n- path EBR similarity as a feature to ranker\n- maintain recal targets from retrival so ranker otpimizes precision\n\n\n\n","autoResize":true,"lineHeight":1.25}],"appState":{"viewBackgroundColor":"#ffffff","lockedMultiSelections":{}},"files":{}}