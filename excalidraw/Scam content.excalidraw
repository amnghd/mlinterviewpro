{"type":"excalidraw","version":2,"source":"https://app.excalidraw.com","metadata":{"id":"743hJOpWMKd","workspace":"6lsqOkFWqjK","name":"Scam content","created":"2025-10-11T05:26:48.262Z","updated":"2025-10-23T18:32:19.857Z","collection":null,"creator":"Alx6QpYT9Vj","updater":"Alx6QpYT9Vj","isPrivate":true,"pinned":false},"elements":[{"id":"agbZE0OriZx_a7U--bIGd","type":"text","x":427.1424352509565,"y":198.9862159434556,"width":1053.4793701171875,"height":2925,"angle":0,"strokeColor":"#1e1e1e","backgroundColor":"transparent","fillStyle":"solid","strokeWidth":2,"strokeStyle":"solid","roughness":1,"opacity":100,"groupIds":[],"frameId":null,"index":"a0","roundness":null,"seed":318574900,"version":5293,"versionNonce":196219127,"isDeleted":false,"boundElements":[],"updated":1761244334397,"link":null,"locked":false,"text":"How would you detect real-time fraudulent or scam content on Facebook?\n\nCQ:\n- what is defined as fraudulent or scam content?  phishing, financial scams, health / medical misinformation,\n- scale of activities? 1B DAU, 2% bad activities, \n- latency: real time (before getting the report)\n- high confidence: bloc, mid confidence:flag for review, low: monitor further\nKPI: maximize detection of scam (improve recall) while having lower than 0.1% false postive?\n - can we assume we have human annotators? user reporting? multi label (financial sca, impersonation)\n\n\n\nHigh level:\n- KPI improve recall for scam detection, while keep FPR < 0.1% as gaurdrail (successful apeal rate)\n- two stage system (lightweight for filtering - distilled), heavy weight calibrated (Dealing with levels)\n- serving multi output calibrated (ban, demote, monitor)\n- multi task classification task \n- input (user + activities)=> output probability of scam for each class => sets of actions\n- light classifier > 0.999 => block right away, 0.1 fine\n- rest goes to heavy ranker\n\nData engineering:\n- Labels:\n-- hand crafted: annotators, high quality, expensive (good for eval golden set)\n-- interactions: reports (different types)\n\n- tables:\n-- user, demographics, start date, location, ip address\n-- user interactions, comments, posts, shares, likes, etc\n\n- features:\n-- comments, posts, message text (BERT, can be SFT'ed to capture trust and safety cases)- embeddings\n-- user id embeddings (similar users can be captured in embedding space)\n-- user age, user location, user sequence of IPs (shows VPN, IP rotation)\n-- user variance in post space (copy and paste same context) = (variance of embeddings of last N posts)\n-- user circadian rhythm\n-- user diversity of connections (all connections follow each other , or dont follow at all)\n-- user sequence of activities (fed to a user model)\n-- user age of account\n-- user belongness to cluster of problematic ids\ndynamic and static features\n\n\nModeling techniques:\n- early fusion for content (image, video, etc) => though heavy work together best\n\n- XGBoost good for interpretability and dealing with sparse data\n- DNN (wide and deep) works better with embedding space, good for continual learning\n- loss function: weighted BCE (better focal loss to deal with easy cases not to dominate) on all each head\n- use MMOE given tasks nature are quite different\n-- explicitly models the relationship between different scam types (tasks) by allowing shared knowledge\n--- while giving each task dedicated expert networks\n- use layer norm and resneet (With rezero) for stabilized results\n\nfocal loss\n(Focusing Parameter): This term down-weights the loss contributed by easy examples\n\n\nModel training:\n- very imabalnced, use minority weighed loss, or down sampling\n- use caliberation layer to bring proba to same ground for all\n- we can use isotonic regression or plat scaling (based on the buckets of post calibeartion)\n\nContinuous learning:\n- triggered by drift in input (should be quick)\n- supplemented by daily triggered\n- online (streaming update of last layer)\n\nEvaluation:\n- recall @ 90 precision\n- pr AUC\n- precision\n- false positive rate\n\n- online:\n-- capture \n-- prevalence\n-- harmful impression\n-- proactive rate\n-- report count per category.\n-- appeal rate per category\n-- appeal rate per demographic\n\n\nServing:\nuser -> lightweight filter => heavy model\n\nlightweight\n> 99.9% right away drop\n> 50% move to next step\n\nheavy weight\n> 80% ban\n> 55 % limit\n>45-55% send for mannaul review (also use manual review as labels) => strong labels\n<45 monitor : add to cluster for monitoring (also use as a feature) => cluser of ids\n\n\n\nDeployment:\nshadowing=> check offline\ncanarying=> check small DC\nA/B => recall on successful appeal (precision drop)\nmulti arm bandit\n\nBias:\nServing bias? we dont really have a sense of bias as we are not ranking\nFairness: making sure target country and language are broken down\n\n\nAlert:\n- quality of the model\n- significant drift in input data\n- latency\n- request failure\n- CPU, GPU duty cycle\n- log interactions and features for TSS as well as future training","fontSize":20,"fontFamily":5,"textAlign":"left","verticalAlign":"top","containerId":null,"originalText":"How would you detect real-time fraudulent or scam content on Facebook?\n\nCQ:\n- what is defined as fraudulent or scam content?  phishing, financial scams, health / medical misinformation,\n- scale of activities? 1B DAU, 2% bad activities, \n- latency: real time (before getting the report)\n- high confidence: bloc, mid confidence:flag for review, low: monitor further\nKPI: maximize detection of scam (improve recall) while having lower than 0.1% false postive?\n - can we assume we have human annotators? user reporting? multi label (financial sca, impersonation)\n\n\n\nHigh level:\n- KPI improve recall for scam detection, while keep FPR < 0.1% as gaurdrail (successful apeal rate)\n- two stage system (lightweight for filtering - distilled), heavy weight calibrated (Dealing with levels)\n- serving multi output calibrated (ban, demote, monitor)\n- multi task classification task \n- input (user + activities)=> output probability of scam for each class => sets of actions\n- light classifier > 0.999 => block right away, 0.1 fine\n- rest goes to heavy ranker\n\nData engineering:\n- Labels:\n-- hand crafted: annotators, high quality, expensive (good for eval golden set)\n-- interactions: reports (different types)\n\n- tables:\n-- user, demographics, start date, location, ip address\n-- user interactions, comments, posts, shares, likes, etc\n\n- features:\n-- comments, posts, message text (BERT, can be SFT'ed to capture trust and safety cases)- embeddings\n-- user id embeddings (similar users can be captured in embedding space)\n-- user age, user location, user sequence of IPs (shows VPN, IP rotation)\n-- user variance in post space (copy and paste same context) = (variance of embeddings of last N posts)\n-- user circadian rhythm\n-- user diversity of connections (all connections follow each other , or dont follow at all)\n-- user sequence of activities (fed to a user model)\n-- user age of account\n-- user belongness to cluster of problematic ids\ndynamic and static features\n\n\nModeling techniques:\n- early fusion for content (image, video, etc) => though heavy work together best\n\n- XGBoost good for interpretability and dealing with sparse data\n- DNN (wide and deep) works better with embedding space, good for continual learning\n- loss function: weighted BCE (better focal loss to deal with easy cases not to dominate) on all each head\n- use MMOE given tasks nature are quite different\n-- explicitly models the relationship between different scam types (tasks) by allowing shared knowledge\n--- while giving each task dedicated expert networks\n- use layer norm and resneet (With rezero) for stabilized results\n\nfocal loss\n(Focusing Parameter): This term down-weights the loss contributed by easy examples\n\n\nModel training:\n- very imabalnced, use minority weighed loss, or down sampling\n- use caliberation layer to bring proba to same ground for all\n- we can use isotonic regression or plat scaling (based on the buckets of post calibeartion)\n\nContinuous learning:\n- triggered by drift in input (should be quick)\n- supplemented by daily triggered\n- online (streaming update of last layer)\n\nEvaluation:\n- recall @ 90 precision\n- pr AUC\n- precision\n- false positive rate\n\n- online:\n-- capture \n-- prevalence\n-- harmful impression\n-- proactive rate\n-- report count per category.\n-- appeal rate per category\n-- appeal rate per demographic\n\n\nServing:\nuser -> lightweight filter => heavy model\n\nlightweight\n> 99.9% right away drop\n> 50% move to next step\n\nheavy weight\n> 80% ban\n> 55 % limit\n>45-55% send for mannaul review (also use manual review as labels) => strong labels\n<45 monitor : add to cluster for monitoring (also use as a feature) => cluser of ids\n\n\n\nDeployment:\nshadowing=> check offline\ncanarying=> check small DC\nA/B => recall on successful appeal (precision drop)\nmulti arm bandit\n\nBias:\nServing bias? we dont really have a sense of bias as we are not ranking\nFairness: making sure target country and language are broken down\n\n\nAlert:\n- quality of the model\n- significant drift in input data\n- latency\n- request failure\n- CPU, GPU duty cycle\n- log interactions and features for TSS as well as future training","autoResize":true,"lineHeight":1.25}],"appState":{"viewBackgroundColor":"#ffffff","lockedMultiSelections":{}},"files":{}}