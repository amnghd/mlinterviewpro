{"type":"excalidraw","version":2,"source":"https://app.excalidraw.com","metadata":{"id":"22I8pefqta1","workspace":"6lsqOkFWqjK","name":"Bot detection in social media","created":"2025-10-11T01:06:07.022Z","updated":"2025-10-23T19:36:16.468Z","collection":null,"creator":"Alx6QpYT9Vj","updater":"Alx6QpYT9Vj","isPrivate":true,"pinned":false},"elements":[{"id":"6oJIfzAhlYPCWXs0mxqh-","type":"text","x":251.2890625,"y":158.125,"width":1112.6790771484375,"height":1600,"angle":0,"strokeColor":"#1e1e1e","backgroundColor":"transparent","fillStyle":"solid","strokeWidth":2,"strokeStyle":"solid","roughness":1,"opacity":100,"groupIds":[],"frameId":null,"index":"a0","roundness":null,"seed":1837530036,"version":4728,"versionNonce":377119865,"isDeleted":false,"boundElements":[],"updated":1761248172373,"link":null,"locked":false,"text":"Detect bots in social media\n=\n\nCQ\n- what social media? \n- what is the latency budget? real time?\n- KPI maximizing bot detection (recall) while minimizing precision drop?\n- FPR < 1% as guardrail ? \n- assuming we are targetting single bots?\n- demoting posts, blocking (allow report)\n\n\nHigh level:\n- two stage architecture:\n-- light weight maximize throughput, low latency, simple MLP, easy features\n--- move high likelihood cases to next step? \n-- heavy model: XGBoost, DNN, or GNN => calibrate => take action\n\n\nData engineering:\n- label (core)\n-- manual annotators: high precision, low volume, used for active learning\n-- user generated report: noisy, low precision, high volume (lower weight in loss)\n-- heuristic: clusters of accounts sharing ip or exhibiting similar behavior\n\n- label (active learning)\n-- use heavy model to predict proba (0.4-0.6)\n--- sample from them and give to annotators\n\n- no label (unsupervised learning)\n-- runs on allowed accounts (after weak model) to flag outlier behavior\nlabels are feedback to continual learning to the main model\n\n\nFeatures:\n- we use tree based model (interpretable, handles sparse data (for new account needed)), non-linear\n- behavioral sequence (too precise, too fast, non-human)\n-- inter event distribution (variance between posts)\n-- circadian rhythm\n\n- network topology (coordinated behavior)\n-- following people who dont follow each others\n-- connection to know bots\n\n- similarity features:\n-- generate embedding for all banned bots (content embeddings, and activity embeddings)\n-- for any new action by user (content, action), immediate genrate vector and query ANN)\n-- get top k (100) closest bots, how many fall within a small radius (this is quite strong feature)\n\nServing:\naction layer:\n- model must be calibrated (to be used against a threshold)\n-- high proba: ban remove\n-- limit, demot content: (reduce visibility, restrict request, minimize impact from FN, while preventing false positive)\n-- near decision proba: go for review (also use as label later)\n\n\n\nEvaluation:\n- offline:\n-- time stratified validation: train on time Q1, test on Q2\n- online;\n-- A/B test reduce bot interaction per legitimate users, while maintaining FPR\n","fontSize":20,"fontFamily":5,"textAlign":"left","verticalAlign":"top","containerId":null,"originalText":"Detect bots in social media\n=\n\nCQ\n- what social media? \n- what is the latency budget? real time?\n- KPI maximizing bot detection (recall) while minimizing precision drop?\n- FPR < 1% as guardrail ? \n- assuming we are targetting single bots?\n- demoting posts, blocking (allow report)\n\n\nHigh level:\n- two stage architecture:\n-- light weight maximize throughput, low latency, simple MLP, easy features\n--- move high likelihood cases to next step? \n-- heavy model: XGBoost, DNN, or GNN => calibrate => take action\n\n\nData engineering:\n- label (core)\n-- manual annotators: high precision, low volume, used for active learning\n-- user generated report: noisy, low precision, high volume (lower weight in loss)\n-- heuristic: clusters of accounts sharing ip or exhibiting similar behavior\n\n- label (active learning)\n-- use heavy model to predict proba (0.4-0.6)\n--- sample from them and give to annotators\n\n- no label (unsupervised learning)\n-- runs on allowed accounts (after weak model) to flag outlier behavior\nlabels are feedback to continual learning to the main model\n\n\nFeatures:\n- we use tree based model (interpretable, handles sparse data (for new account needed)), non-linear\n- behavioral sequence (too precise, too fast, non-human)\n-- inter event distribution (variance between posts)\n-- circadian rhythm\n\n- network topology (coordinated behavior)\n-- following people who dont follow each others\n-- connection to know bots\n\n- similarity features:\n-- generate embedding for all banned bots (content embeddings, and activity embeddings)\n-- for any new action by user (content, action), immediate genrate vector and query ANN)\n-- get top k (100) closest bots, how many fall within a small radius (this is quite strong feature)\n\nServing:\naction layer:\n- model must be calibrated (to be used against a threshold)\n-- high proba: ban remove\n-- limit, demot content: (reduce visibility, restrict request, minimize impact from FN, while preventing false positive)\n-- near decision proba: go for review (also use as label later)\n\n\n\nEvaluation:\n- offline:\n-- time stratified validation: train on time Q1, test on Q2\n- online;\n-- A/B test reduce bot interaction per legitimate users, while maintaining FPR\n","autoResize":true,"lineHeight":1.25}],"appState":{"viewBackgroundColor":"#ffffff","lockedMultiSelections":{}},"files":{}}