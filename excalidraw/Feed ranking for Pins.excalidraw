{"type":"excalidraw","version":2,"source":"https://app.excalidraw.com","metadata":{"id":"4SwVjz9qDVt","workspace":"6lsqOkFWqjK","name":"Feed ranking for Pins","created":"2025-10-15T23:56:02.211Z","updated":"2025-10-23T18:17:25.245Z","collection":null,"creator":"Alx6QpYT9Vj","updater":"Alx6QpYT9Vj","isPrivate":true,"pinned":false},"elements":[{"id":"cMUssl5me1xeTsA6dVaix","type":"text","x":580.2838974293365,"y":369.1241237499096,"width":1077.767822265625,"height":4975,"angle":0,"strokeColor":"#1e1e1e","backgroundColor":"transparent","fillStyle":"solid","strokeWidth":2,"strokeStyle":"solid","roughness":1,"opacity":100,"groupIds":[],"frameId":null,"index":"a4","roundness":null,"seed":1626535855,"version":8966,"versionNonce":1510482359,"isDeleted":false,"boundElements":[],"updated":1761243441023,"link":null,"locked":false,"text":"Recommend Pins that user might engage with in Pinterst\n\n\nCQ:\n- what is scale? DAU, QPS (100M, 50kqps)\n- latency budget? 100 ms (stay 40 mili secodns)\n- # pins (B)\n- pins mostly images, text on image, key words, hash tags\n- follow people, pages\n- interaction data? like, comment, share, click,  bookmark\n- multi lingual? English\n- \n\nKPIs:\n- maximize user engagement (click: baity, bookmark:sparse) => weighted sum of engagements metrics,\n- DAU increase (return rate) \n- gaurdrail this on churn, reports, dislikes, latency, TPU utilization, (potential Ads revenue) => seperate\ninteactions vs monetization\n\n\n\nHigh level design:\n- input user request => ranked elements based on the users engagement potential\n- bookmarket : probablity of bookmark (composite metric)=> rating \n- <user event> => ranked ratings of engagement => rank \n- train serpaetenly on all those topics \n- learning to rank (pointwise, pairwise, and listwise) (pointwise)\n\nDat contruction:\n- label\n-- clicks seperatey, bookmarek, share, comment sentiment\n-- weigthed metric (share higher weight, click lower weight) => each request we can build this label (positive\nmeasure) compositve label\n- negative labels\n-- cases where there is no enagement after impressing the pins\n- manual labels: => overkills => user p13n => annotators (noisy, biased) X\n\n- data engineering\n-- user\n-- request (context)\n-- pin\n\nDNN \n\n- feature engineering\n-- user: user id (hashed, embedding) \n-- MAU, YAU (5B) => table => a lot storage > hash function=> dimension that we find reasonably (to run\ninference) => collistion (third root of cardinality) => pracice quite efficient, fast,\n-- embeddign layer (fed to bottom of a DNN) => embeding layers learn similariy (cotrained on the final goal)\n\n-- demographics (age, gender => bucketized, onehot)\n-- user clusters (offlines=> clusters user) => one hot\n-- user embeddings (sequential model) => pretrained model => \n-- past history (# pins liked, # pins impressed ) # last months\n-- broken by pin category, pin subcategory\n\nrequest\n-- DOW (one hotted) , TOD (bucket) one hotted\n-- device type (one hotted), device id (hashe + embedding), device netowrk (proxy of social status)\n-- IP (praivacy concern, GDPR, DMA) => opt in \n\n\nPin \n-- image: (nornaliziton, denoising, scaling) => static feature => pass these pretrained (GEmini embedding, or\nAutoecoder, SIMCLR) => stored \n-- cotrained these with main model (encoder layer of autoencoder, sicmclr)=> cheaper + cotrained richer signal\n-- text: statics (high quality pretrained) =<> key, value\n-- tokenaization, nroamialtion, BERT (pretraiedn, ids, embeddings)\n-- cotrained with main model (BERT) encoder\n-- TFIDF, BOW (context inaware)\n-- tags (bow) , bigram, triggra, => \n-- posts history (# of $INTERACTION$ (last 3, 7, 30 days)) => nromalize, bucketized, => skewed => one\nhot\n\n\n-- post channel owner ID (hashed, embedded) => finding similar IDS\n\n\n\nFeature store \n-- training and test onpar (TTS)= > unreliable results\nFeature dynamic, static\n-- dynamic (# of post clicks)=> run in real time (bottleneck) latency =<> reduce\n-- static (user age) pre comptued => neear real tine\n\nSub 100 MS\nSLM => distilled \ngenreation (positon of them)\ntransforer => encocedr=> user seequnce features => \ndecoder head (complex and heavy)\n\nrecsyus + LLM \n\ngenerating itesm that are similar to this new item\n\n\n\nModel architecture (system)\n\n\nRetrival\n=> two tower, ANN, simpler sets of features\n\n\n- learn different engamgeent (sepreata modesl click, bookmarkt) =\n-- seperate training (mission critical)=> one specific, bookmark (1% click) => positive labels\n-- multitask learning (to train together bottom sahred tower) => transfer learning betwees \n-- sparse model learning, engineering velocity, maintenance, serving training cost\n- negative transer of knoweldge (study)=> MMOE (different gating for each task)=> expert seperatly learn\nfor differnt task (focals loss)=> model to not overfit on mahortiy label\n-- feature crosses (embedding based DCN, DCN V2), (embeding FM)=> continal learning\n-- XGBOOST (continual learning X)\n\nMMOE + DCN  V2 + MH model\n\n\n-- MTL => different, transfer learning => for each event have different taks (share) =>. CE => \n- metric that is used to rank is that weighted combination\n- loss (weighted sum of losses of each task)\nCE => click, share, bookmark\nMSE => comment sentiment (computed offline) 1-5 rating SA=> label\n\nModel training\n- sampling \n-- skewed data set => many more negatives=> weighted loss (number of samples is low), down sample \n-- caliberation => Ads (compute the bid)=> isotonic, plat scaling\n-- downs sampling =< headache, tech debt, compute 2-3X downs sampling => sample , regualization\n\nEvaluation\n- offline:\n-- ratings are contnous-\n-- called NDCG => compute relevance and ranking at same by discount relevance by position\n-- follow CE, NCE for imporattnt ask (bookmarkt)\n\n- online:\n-- DAU, churn rate\n-- CTR\n-- bookmark rate\n-- report rate, dislike rate\n\n-- monitoring\n--- quality, drift, => retraining\n-- latency, failure rate, qps\n\n\nServing\n\n- efficiecnty\n-- AI TPU => efficient\n-- cascaeded we dsciused (retrival, reranker, ranker)\n-- modelings: pruning (layer level), two tower retrival (embedding qt, embeding size optimzation), AQT, caching\n(features, for embedding retrival, predicton)\n\n- contiuneal\n-- fresh => new data=>\n--- regular timing \n--- drift trigger (features , continus, dsitrbuion chanage over time (t-test, z-test)- practical bounds 10%,\ncageoti chisquare) -> tighted, lossend\n--- online training: new batch of prediction, training, catastrohoc forgetting (learning rate decay)\n\nDeployment\n- shadowing => offline works well (distribuytion of predciton)\n- canarying ((1DC)) => follow gaurdrails => drop it\n- A/B testing\n- holdback\n- multi arm badnit (revenue, LTV) => explra, explotion ration=> expliration contatn while check different arms\n\n\nAdvanced topics (biases, cold start, exploration)\n- reranker = freshness, diversity\n-- (1) remove duplicates, previously watched, (2) fresh within x hours (heuristic), (3) diverse (penality) non-\ndiverse (embedding consine simiary)\n\n- trendy, populars are shown (oldest date), users follows, connection (last X days) are shown as well\n\n- biases\n-- serving: e-greedy exploration 1-e => ranked, e random results (simpler model)=> graurdaliran churn (study e\nvs chrun)\n-- position\n--- add positon as a feautre, at aserving give all of them same poiton\n\n-- popularity\n--- penalty (reranker)\n--- multiplier ranked result (popular)\n\n\n- cold start\n (from previous recsys => matrix factorization, CB, CBF) => ID based => we dont id\nretrival (context features, user features ID based) => help with both cold\n-- feature drops on IDs (10% drop study) => model trains better when these features (memorize)\n\n-- item cold start\n--- content based filtering => similar features => generate similar items (domian knowedlge to generate those\nfeatures) => we can use this in parallel to our retrival (candidate gnerateor on new content)=> heavy ranker\n=> much stronger sets of feature => \n-- user cold start\n--- put in their interest, get as much infrormation (simpler model)=> give\n\n","fontSize":20,"fontFamily":5,"textAlign":"left","verticalAlign":"top","containerId":null,"originalText":"Recommend Pins that user might engage with in Pinterst\n\n\nCQ:\n- what is scale? DAU, QPS (100M, 50kqps)\n- latency budget? 100 ms (stay 40 mili secodns)\n- # pins (B)\n- pins mostly images, text on image, key words, hash tags\n- follow people, pages\n- interaction data? like, comment, share, click,  bookmark\n- multi lingual? English\n- \n\nKPIs:\n- maximize user engagement (click: baity, bookmark:sparse) => weighted sum of engagements metrics,\n- DAU increase (return rate) \n- gaurdrail this on churn, reports, dislikes, latency, TPU utilization, (potential Ads revenue) => seperate inteactions vs monetization\n\n\n\nHigh level design:\n- input user request => ranked elements based on the users engagement potential\n- bookmarket : probablity of bookmark (composite metric)=> rating \n- <user event> => ranked ratings of engagement => rank \n- train serpaetenly on all those topics \n- learning to rank (pointwise, pairwise, and listwise) (pointwise)\n\nDat contruction:\n- label\n-- clicks seperatey, bookmarek, share, comment sentiment\n-- weigthed metric (share higher weight, click lower weight) => each request we can build this label (positive measure) compositve label\n- negative labels\n-- cases where there is no enagement after impressing the pins\n- manual labels: => overkills => user p13n => annotators (noisy, biased) X\n\n- data engineering\n-- user\n-- request (context)\n-- pin\n\nDNN \n\n- feature engineering\n-- user: user id (hashed, embedding) \n-- MAU, YAU (5B) => table => a lot storage > hash function=> dimension that we find reasonably (to run inference) => collistion (third root of cardinality) => pracice quite efficient, fast,\n-- embeddign layer (fed to bottom of a DNN) => embeding layers learn similariy (cotrained on the final goal)\n\n-- demographics (age, gender => bucketized, onehot)\n-- user clusters (offlines=> clusters user) => one hot\n-- user embeddings (sequential model) => pretrained model => \n-- past history (# pins liked, # pins impressed ) # last months\n-- broken by pin category, pin subcategory\n\nrequest\n-- DOW (one hotted) , TOD (bucket) one hotted\n-- device type (one hotted), device id (hashe + embedding), device netowrk (proxy of social status)\n-- IP (praivacy concern, GDPR, DMA) => opt in \n\n\nPin \n-- image: (nornaliziton, denoising, scaling) => static feature => pass these pretrained (GEmini embedding, or Autoecoder, SIMCLR) => stored \n-- cotrained these with main model (encoder layer of autoencoder, sicmclr)=> cheaper + cotrained richer signal\n-- text: statics (high quality pretrained) =<> key, value\n-- tokenaization, nroamialtion, BERT (pretraiedn, ids, embeddings)\n-- cotrained with main model (BERT) encoder\n-- TFIDF, BOW (context inaware)\n-- tags (bow) , bigram, triggra, => \n-- posts history (# of $INTERACTION$ (last 3, 7, 30 days)) => nromalize, bucketized, => skewed => one hot\n\n\n-- post channel owner ID (hashed, embedded) => finding similar IDS\n\n\n\nFeature store \n-- training and test onpar (TTS)= > unreliable results\nFeature dynamic, static\n-- dynamic (# of post clicks)=> run in real time (bottleneck) latency =<> reduce\n-- static (user age) pre comptued => neear real tine\n\nSub 100 MS\nSLM => distilled \ngenreation (positon of them)\ntransforer => encocedr=> user seequnce features => \ndecoder head (complex and heavy)\n\nrecsyus + LLM \n\ngenerating itesm that are similar to this new item\n\n\n\nModel architecture (system)\n\n\nRetrival\n=> two tower, ANN, simpler sets of features\n\n\n- learn different engamgeent (sepreata modesl click, bookmarkt) =\n-- seperate training (mission critical)=> one specific, bookmark (1% click) => positive labels\n-- multitask learning (to train together bottom sahred tower) => transfer learning betwees \n-- sparse model learning, engineering velocity, maintenance, serving training cost\n- negative transer of knoweldge (study)=> MMOE (different gating for each task)=> expert seperatly learn for differnt task (focals loss)=> model to not overfit on mahortiy label\n-- feature crosses (embedding based DCN, DCN V2), (embeding FM)=> continal learning\n-- XGBOOST (continual learning X)\n\nMMOE + DCN  V2 + MH model\n\n\n-- MTL => different, transfer learning => for each event have different taks (share) =>. CE => \n- metric that is used to rank is that weighted combination\n- loss (weighted sum of losses of each task)\nCE => click, share, bookmark\nMSE => comment sentiment (computed offline) 1-5 rating SA=> label\n\nModel training\n- sampling \n-- skewed data set => many more negatives=> weighted loss (number of samples is low), down sample \n-- caliberation => Ads (compute the bid)=> isotonic, plat scaling\n-- downs sampling =< headache, tech debt, compute 2-3X downs sampling => sample , regualization\n\nEvaluation\n- offline:\n-- ratings are contnous-\n-- called NDCG => compute relevance and ranking at same by discount relevance by position\n-- follow CE, NCE for imporattnt ask (bookmarkt)\n\n- online:\n-- DAU, churn rate\n-- CTR\n-- bookmark rate\n-- report rate, dislike rate\n\n-- monitoring\n--- quality, drift, => retraining\n-- latency, failure rate, qps\n\n\nServing\n\n- efficiecnty\n-- AI TPU => efficient\n-- cascaeded we dsciused (retrival, reranker, ranker)\n-- modelings: pruning (layer level), two tower retrival (embedding qt, embeding size optimzation), AQT, caching (features, for embedding retrival, predicton)\n\n- contiuneal\n-- fresh => new data=>\n--- regular timing \n--- drift trigger (features , continus, dsitrbuion chanage over time (t-test, z-test)- practical bounds 10%, cageoti chisquare) -> tighted, lossend\n--- online training: new batch of prediction, training, catastrohoc forgetting (learning rate decay)\n\nDeployment\n- shadowing => offline works well (distribuytion of predciton)\n- canarying ((1DC)) => follow gaurdrails => drop it\n- A/B testing\n- holdback\n- multi arm badnit (revenue, LTV) => explra, explotion ration=> expliration contatn while check different arms\n\n\nAdvanced topics (biases, cold start, exploration)\n- reranker = freshness, diversity\n-- (1) remove duplicates, previously watched, (2) fresh within x hours (heuristic), (3) diverse (penality) non-diverse (embedding consine simiary)\n\n- trendy, populars are shown (oldest date), users follows, connection (last X days) are shown as well\n\n- biases\n-- serving: e-greedy exploration 1-e => ranked, e random results (simpler model)=> graurdaliran churn (study e vs chrun)\n-- position\n--- add positon as a feautre, at aserving give all of them same poiton\n\n-- popularity\n--- penalty (reranker)\n--- multiplier ranked result (popular)\n\n\n- cold start\n (from previous recsys => matrix factorization, CB, CBF) => ID based => we dont id\nretrival (context features, user features ID based) => help with both cold\n-- feature drops on IDs (10% drop study) => model trains better when these features (memorize)\n\n-- item cold start\n--- content based filtering => similar features => generate similar items (domian knowedlge to generate those features) => we can use this in parallel to our retrival (candidate gnerateor on new content)=> heavy ranker => much stronger sets of feature => \n-- user cold start\n--- put in their interest, get as much infrormation (simpler model)=> give\n\n","autoResize":false,"lineHeight":1.25},{"id":"1DqRPKpSpB9Qm0T9Pb9jp","type":"rectangle","x":1922.8168397538457,"y":851.1198145607367,"width":269.049560546875,"height":129.60504150390625,"angle":0,"strokeColor":"#1e1e1e","backgroundColor":"transparent","fillStyle":"solid","strokeWidth":2,"strokeStyle":"solid","roughness":1,"opacity":100,"groupIds":[],"frameId":null,"index":"a5","roundness":{"type":3},"seed":73830959,"version":47,"versionNonce":1227352129,"isDeleted":false,"boundElements":[],"updated":1760570437195,"link":null,"locked":false},{"id":"0oMiczRhK9BsCPrxr00lV","type":"arrow","x":1801.623358308533,"y":910.4600855568304,"width":125.9027099609375,"height":2.62152099609375,"angle":0,"strokeColor":"#1e1e1e","backgroundColor":"transparent","fillStyle":"solid","strokeWidth":2,"strokeStyle":"solid","roughness":1,"opacity":100,"groupIds":[],"frameId":null,"index":"a7","roundness":{"type":2},"seed":187543823,"version":39,"versionNonce":959846657,"isDeleted":false,"boundElements":[],"updated":1760570443033,"link":null,"locked":false,"points":[[0,0],[125.9027099609375,2.62152099609375]],"lastCommittedPoint":null,"startBinding":null,"endBinding":null,"startArrowhead":null,"endArrowhead":"arrow","elbowed":false},{"id":"0k-OXnz6eLlwdh8BucmeD","type":"text","x":2017.083319246033,"y":892.2899500587836,"width":194.75987243652344,"height":50,"angle":0,"strokeColor":"#1e1e1e","backgroundColor":"transparent","fillStyle":"solid","strokeWidth":2,"strokeStyle":"solid","roughness":1,"opacity":100,"groupIds":[],"frameId":null,"index":"a8","roundness":null,"seed":1679559151,"version":79,"versionNonce":1634896847,"isDeleted":false,"boundElements":[],"updated":1760570536784,"link":null,"locked":false,"text":"filtering\nretrival (two tower)","fontSize":20,"fontFamily":5,"textAlign":"left","verticalAlign":"top","containerId":null,"originalText":"filtering\nretrival (two tower)","autoResize":true,"lineHeight":1.25},{"id":"s6v-MTAK4BoPZq3HgXt73","type":"text","x":1857.540838777283,"y":945.8584620216741,"width":47.41996765136719,"height":25,"angle":0,"strokeColor":"#1e1e1e","backgroundColor":"transparent","fillStyle":"solid","strokeWidth":2,"strokeStyle":"solid","roughness":1,"opacity":100,"groupIds":[],"frameId":null,"index":"a9","roundness":null,"seed":1848147535,"version":35,"versionNonce":1498931873,"isDeleted":false,"boundElements":[],"updated":1760570459894,"link":null,"locked":false,"text":"O(B)","fontSize":20,"fontFamily":5,"textAlign":"left","verticalAlign":"top","containerId":null,"originalText":"O(B)","autoResize":true,"lineHeight":1.25},{"id":"cy2644uCA6E_Q2IFMk4nj","type":"text","x":2209.222235261658,"y":948.2222315529242,"width":76.23997497558594,"height":25,"angle":0,"strokeColor":"#1e1e1e","backgroundColor":"transparent","fillStyle":"solid","strokeWidth":2,"strokeStyle":"solid","roughness":1,"opacity":100,"groupIds":[],"frameId":null,"index":"aA","roundness":null,"seed":1875305519,"version":11,"versionNonce":1475617071,"isDeleted":false,"boundElements":[],"updated":1760570514004,"link":null,"locked":false,"text":"o(1000)","fontSize":20,"fontFamily":5,"textAlign":"left","verticalAlign":"top","containerId":null,"originalText":"o(1000)","autoResize":true,"lineHeight":1.25},{"id":"JPnQpbQYnYQoSED-tIsvQ","type":"text","x":1986.7778023554956,"y":1001.8888981312876,"width":255.93978881835938,"height":50,"angle":0,"strokeColor":"#1e1e1e","backgroundColor":"transparent","fillStyle":"solid","strokeWidth":2,"strokeStyle":"solid","roughness":1,"opacity":100,"groupIds":[],"frameId":null,"index":"aB","roundness":null,"seed":88229231,"version":51,"versionNonce":1358871471,"isDeleted":false,"boundElements":[],"updated":1760570475816,"link":null,"locked":false,"text":"latency aware\nrecall aware (minimized FN)","fontSize":20,"fontFamily":5,"textAlign":"left","verticalAlign":"top","containerId":null,"originalText":"latency aware\nrecall aware (minimized FN)","autoResize":true,"lineHeight":1.25},{"id":"yVbtI8llMVnj7WVjnMcID","type":"arrow","x":2196.675385363308,"y":901.8533146351939,"width":139.5269775390625,"height":2.16143798828125,"angle":0,"strokeColor":"#1e1e1e","backgroundColor":"transparent","fillStyle":"solid","strokeWidth":2,"strokeStyle":"solid","roughness":1,"opacity":100,"groupIds":[],"frameId":null,"index":"aC","roundness":{"type":2},"seed":125361135,"version":32,"versionNonce":530581519,"isDeleted":false,"boundElements":[],"updated":1760570479660,"link":null,"locked":false,"points":[[0,0],[139.5269775390625,-2.16143798828125]],"lastCommittedPoint":null,"startBinding":{"elementId":"1DqRPKpSpB9Qm0T9Pb9jp","focus":-0.17807152913239518,"gap":4.808985062587453},"endBinding":null,"startArrowhead":null,"endArrowhead":"arrow","elbowed":false},{"id":"djmbC-g0-mv-F_xRmbggE","type":"rectangle","x":2345.3820504023706,"y":834.4661686391001,"width":283.6588134765625,"height":148.61981201171875,"angle":0,"strokeColor":"#1e1e1e","backgroundColor":"transparent","fillStyle":"solid","strokeWidth":2,"strokeStyle":"solid","roughness":1,"opacity":100,"groupIds":[],"frameId":null,"index":"aD","roundness":{"type":3},"seed":2051666945,"version":60,"versionNonce":766301071,"isDeleted":false,"boundElements":[{"id":"7FYQmoUe13QqtnMK06N5b","type":"arrow"}],"updated":1760570496507,"link":null,"locked":false},{"id":"tcrJekIB8ivPAFdHictf3","type":"text","x":2430.6432808711206,"y":902.8125126332408,"width":210.47982788085938,"height":50,"angle":0,"strokeColor":"#1e1e1e","backgroundColor":"transparent","fillStyle":"solid","strokeWidth":2,"strokeStyle":"solid","roughness":1,"opacity":100,"groupIds":[],"frameId":null,"index":"aF","roundness":null,"seed":1767951631,"version":63,"versionNonce":500786273,"isDeleted":false,"boundElements":[],"updated":1760570548508,"link":null,"locked":false,"text":"ranking stage\n(light ranker distilled)","fontSize":20,"fontFamily":5,"textAlign":"left","verticalAlign":"top","containerId":null,"originalText":"ranking stage\n(light ranker distilled)","autoResize":true,"lineHeight":1.25},{"id":"zYbPAZTlH92fODevANKOm","type":"text","x":2395.7778023554956,"y":1002.8888981312876,"width":172.33984375,"height":50,"angle":0,"strokeColor":"#1e1e1e","backgroundColor":"transparent","fillStyle":"solid","strokeWidth":2,"strokeStyle":"solid","roughness":1,"opacity":100,"groupIds":[],"frameId":null,"index":"aG","roundness":null,"seed":896443887,"version":21,"versionNonce":1991145583,"isDeleted":false,"boundElements":[],"updated":1760570493494,"link":null,"locked":false,"text":"maximize precision\n","fontSize":20,"fontFamily":5,"textAlign":"left","verticalAlign":"top","containerId":null,"originalText":"maximize precision\n","autoResize":true,"lineHeight":1.25},{"id":"7FYQmoUe13QqtnMK06N5b","type":"arrow","x":2638.3725073249248,"y":894.7613147511892,"width":209.626708984375,"height":0,"angle":0,"strokeColor":"#1e1e1e","backgroundColor":"transparent","fillStyle":"solid","strokeWidth":2,"strokeStyle":"solid","roughness":1,"opacity":100,"groupIds":[],"frameId":null,"index":"aH","roundness":{"type":2},"seed":1605041601,"version":11,"versionNonce":510384495,"isDeleted":false,"boundElements":[],"updated":1760570496507,"link":null,"locked":false,"points":[[0,0],[209.626708984375,0]],"lastCommittedPoint":null,"startBinding":{"elementId":"djmbC-g0-mv-F_xRmbggE","focus":-0.18859881067088413,"gap":9.33164344599163},"endBinding":null,"startArrowhead":null,"endArrowhead":"arrow","elbowed":false},{"id":"XAyJHhbnSDWSnI8nizv0p","type":"text","x":2688.4246313483623,"y":935.2865222707204,"width":199.0198516845703,"height":50,"angle":0,"strokeColor":"#1e1e1e","backgroundColor":"transparent","fillStyle":"solid","strokeWidth":2,"strokeStyle":"solid","roughness":1,"opacity":100,"groupIds":[],"frameId":null,"index":"aI","roundness":null,"seed":1059531937,"version":44,"versionNonce":334111055,"isDeleted":false,"boundElements":[],"updated":1760570503417,"link":null,"locked":false,"text":"ranked list of items \n(weighted score)","fontSize":20,"fontFamily":5,"textAlign":"left","verticalAlign":"top","containerId":null,"originalText":"ranked list of items \n(weighted score)","autoResize":true,"lineHeight":1.25},{"id":"8R47trk_CmnXAYQG-SH5d","type":"text","x":2652.916719695667,"y":911.11112571057,"width":66.29997253417969,"height":25,"angle":0,"strokeColor":"#1e1e1e","backgroundColor":"transparent","fillStyle":"solid","strokeWidth":2,"strokeStyle":"solid","roughness":1,"opacity":100,"groupIds":[],"frameId":null,"index":"aJ","roundness":null,"seed":1460012737,"version":11,"versionNonce":1443653761,"isDeleted":false,"boundElements":[],"updated":1760570516450,"link":null,"locked":false,"text":"O(100)","fontSize":20,"fontFamily":5,"textAlign":"left","verticalAlign":"top","containerId":null,"originalText":"O(100)","autoResize":true,"lineHeight":1.25},{"id":"DVQJWzuQszCSJqQczQnyM","type":"text","x":2381.918472195848,"y":753.346387227377,"width":698.1395263671875,"height":25,"angle":0,"strokeColor":"#1e1e1e","backgroundColor":"transparent","fillStyle":"solid","strokeWidth":2,"strokeStyle":"solid","roughness":1,"opacity":100,"groupIds":[],"frameId":null,"index":"aK","roundness":null,"seed":2098462017,"version":102,"versionNonce":371086433,"isDeleted":false,"boundElements":[],"updated":1760570575590,"link":null,"locked":false,"text":"light ranker (distilled on soft labels) => quality loss (quality vs latency)","fontSize":20,"fontFamily":5,"textAlign":"left","verticalAlign":"top","containerId":null,"originalText":"light ranker (distilled on soft labels) => quality loss (quality vs latency)","autoResize":true,"lineHeight":1.25}],"appState":{"viewBackgroundColor":"#ffffff","lockedMultiSelections":{}},"files":{}}