<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ML Coding - MLInterviewPro</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <style>
        .gradient-bg { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); }
        .code-card:hover { transform: translateY(-3px); }
        .premium-blur { filter: blur(4px); pointer-events: none; }
        .collapsible-content { max-height: 0; overflow: hidden; transition: max-height 0.5s ease-out; }
        .collapsible-content.open { max-height: 10000px; }
        pre code { font-size: 13px !important; }
    </style>
</head>
<body class="bg-gray-50">
    <!-- Navigation -->
    <nav class="bg-white shadow-lg sticky top-0 z-50">
        <div class="max-w-7xl mx-auto px-4">
            <div class="flex justify-between items-center h-16">
                <a href="index.html" class="text-2xl font-bold text-purple-600">
                    <i class="fas fa-brain mr-2"></i>MLInterviewPro
                </a>
                <div class="hidden md:flex space-x-6">
                    <a href="leetcode.html" class="text-gray-700 hover:text-purple-600 font-medium">LeetCode</a>
                    <a href="ml-system-design.html" class="text-gray-700 hover:text-purple-600 font-medium">ML System Design</a>
                    <a href="ml-coding.html" class="text-purple-600 font-bold">ML Coding</a>
                    <a href="behavioral.html" class="text-gray-700 hover:text-purple-600 font-medium">Behavioral</a>
                    <a href="cheatsheet.html" class="text-gray-700 hover:text-purple-600 font-medium">Cheatsheet</a>
                    <a href="resources.html" class="text-gray-700 hover:text-purple-600 font-medium">Resources</a>
                    <a href="about.html" class="text-gray-700 hover:text-purple-600 font-medium">About</a>
                </div>
                <a href="https://mentorcruise.com/mentor/AminGhaderi/" target="_blank"
                   class="bg-gradient-to-r from-pink-500 to-purple-600 text-white px-4 py-2 rounded-full font-semibold hover:shadow-lg transition">
                    <i class="fas fa-user-tie mr-2"></i>Book Mentorship
                </a>
            </div>
        </div>
    </nav>

    <!-- Hero with Stats -->
    <section class="gradient-bg text-white py-12">
        <div class="max-w-7xl mx-auto px-4">
            <div class="grid md:grid-cols-4 gap-4 mb-8">
                <div class="bg-white/10 backdrop-blur rounded-xl p-3 text-center">
                    <div class="text-2xl font-bold">+300%</div>
                    <div class="text-xs opacity-80">AI Job Growth (LinkedIn)</div>
                </div>
                <div class="bg-white/10 backdrop-blur rounded-xl p-3 text-center">
                    <div class="text-2xl font-bold">88%</div>
                    <div class="text-xs opacity-80">Companies Using AI (McKinsey)</div>
                </div>
                <div class="bg-white/10 backdrop-blur rounded-xl p-3 text-center">
                    <div class="text-2xl font-bold">$185K+</div>
                    <div class="text-xs opacity-80">Median ML Salary (Forbes)</div>
                </div>
                <div class="bg-white/10 backdrop-blur rounded-xl p-3 text-center">
                    <div class="text-2xl font-bold">+53%</div>
                    <div class="text-xs opacity-80">Salary Increase in 15mo</div>
                </div>
            </div>
            <h1 class="text-4xl font-bold mb-4"><i class="fas fa-code mr-3"></i>ML Coding Interview Prep</h1>
            <p class="text-xl opacity-90">Implement ML algorithms from scratch AND with libraries. Master both for interviews.</p>
        </div>
    </section>

    <!-- Topics Overview -->
    <section class="py-8 bg-white shadow">
        <div class="max-w-7xl mx-auto px-4">
            <div class="grid grid-cols-3 md:grid-cols-6 gap-4 text-center text-sm">
                <div class="p-3 rounded-lg bg-blue-50">
                    <div class="font-bold text-blue-600">KNN</div>
                    <div class="text-xs text-gray-500">Classification</div>
                </div>
                <div class="p-3 rounded-lg bg-green-50">
                    <div class="font-bold text-green-600">SVM</div>
                    <div class="text-xs text-gray-500">Classification</div>
                </div>
                <div class="p-3 rounded-lg bg-purple-50">
                    <div class="font-bold text-purple-600">PCA</div>
                    <div class="text-xs text-gray-500">Dimensionality</div>
                </div>
                <div class="p-3 rounded-lg bg-orange-50">
                    <div class="font-bold text-orange-600">DNN</div>
                    <div class="text-xs text-gray-500">Deep Learning</div>
                </div>
                <div class="p-3 rounded-lg bg-red-50">
                    <div class="font-bold text-red-600">CNN</div>
                    <div class="text-xs text-gray-500">Computer Vision</div>
                </div>
                <div class="p-3 rounded-lg bg-cyan-50">
                    <div class="font-bold text-cyan-600">RNN</div>
                    <div class="text-xs text-gray-500">Sequences</div>
                </div>
            </div>
        </div>
    </section>

    <!-- Free Examples -->
    <section class="py-12">
        <div class="max-w-7xl mx-auto px-4">
            <h2 class="text-2xl font-bold mb-6 flex items-center">
                <i class="fas fa-unlock text-green-500 mr-3"></i>Free Examples - From Scratch & With Libraries
            </h2>

            <div class="space-y-8">
                <!-- KNN -->
                <div class="bg-white rounded-xl shadow-lg overflow-hidden code-card transition-all duration-300">
                    <div class="p-6">
                        <div class="flex items-start justify-between mb-4">
                            <div>
                                <span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium">Classification</span>
                                <span class="bg-green-100 text-green-800 px-3 py-1 rounded-full text-sm font-medium ml-2">Free</span>
                                <h3 class="text-2xl font-bold mt-2">K-Nearest Neighbors (KNN)</h3>
                                <p class="text-gray-600">Instance-based learning algorithm for classification and regression</p>
                            </div>
                        </div>

                        <button onclick="toggleContent('knn')" class="w-full bg-gradient-to-r from-blue-500 to-cyan-500 text-white px-6 py-3 rounded-lg font-semibold hover:shadow-lg transition mb-4">
                            <i class="fas fa-eye mr-2"></i>View Implementation
                        </button>

                        <div id="knn" class="collapsible-content">
                            <!-- Theory -->
                            <div class="bg-blue-50 rounded-lg p-4 mb-4">
                                <h4 class="font-bold text-blue-800 mb-2"><i class="fas fa-lightbulb mr-2"></i>Key Concepts</h4>
                                <ul class="text-sm text-gray-700 space-y-1">
                                    <li><strong>Time Complexity:</strong> O(n*d) per prediction where n=samples, d=dimensions</li>
                                    <li><strong>Space Complexity:</strong> O(n*d) - stores all training data</li>
                                    <li><strong>Key Hyperparameter:</strong> k (number of neighbors) - odd numbers avoid ties</li>
                                    <li><strong>Distance Metric:</strong> Euclidean, Manhattan, or Minkowski</li>
                                </ul>
                            </div>

                            <!-- From Scratch -->
                            <div class="mb-4">
                                <h4 class="font-bold text-gray-800 mb-2"><i class="fab fa-python mr-2"></i>From Scratch (NumPy only)</h4>
                                <pre class="rounded-lg"><code class="language-python">import numpy as np
from collections import Counter

class KNNFromScratch:
    def __init__(self, k=3):
        self.k = k
        self.X_train = None
        self.y_train = None

    def fit(self, X, y):
        """Store training data - KNN is lazy learner"""
        self.X_train = np.array(X)
        self.y_train = np.array(y)
        return self

    def _euclidean_distance(self, x1, x2):
        """Compute Euclidean distance between two points"""
        return np.sqrt(np.sum((x1 - x2) ** 2))

    def _predict_single(self, x):
        """Predict class for a single sample"""
        # Compute distances to all training samples
        distances = [self._euclidean_distance(x, x_train)
                     for x_train in self.X_train]

        # Get indices of k nearest neighbors
        k_indices = np.argsort(distances)[:self.k]

        # Get labels of k nearest neighbors
        k_labels = self.y_train[k_indices]

        # Majority vote
        most_common = Counter(k_labels).most_common(1)
        return most_common[0][0]

    def predict(self, X):
        """Predict classes for multiple samples"""
        X = np.array(X)
        return np.array([self._predict_single(x) for x in X])

    def score(self, X, y):
        """Calculate accuracy"""
        predictions = self.predict(X)
        return np.mean(predictions == y)

# Usage Example
if __name__ == "__main__":
    from sklearn.datasets import load_iris
    from sklearn.model_selection import train_test_split

    # Load data
    iris = load_iris()
    X_train, X_test, y_train, y_test = train_test_split(
        iris.data, iris.target, test_size=0.2, random_state=42
    )

    # Train and evaluate
    knn = KNNFromScratch(k=3)
    knn.fit(X_train, y_train)
    accuracy = knn.score(X_test, y_test)
    print(f"Accuracy: {accuracy:.4f}")  # ~0.97</code></pre>
                            </div>

                            <!-- With Library -->
                            <div>
                                <h4 class="font-bold text-gray-800 mb-2"><i class="fas fa-box mr-2"></i>With Scikit-Learn</h4>
                                <pre class="rounded-lg"><code class="language-python">from sklearn.neighbors import KNeighborsClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler

# Load and split data
iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(
    iris.data, iris.target, test_size=0.2, random_state=42
)

# Scale features (important for distance-based algorithms!)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train KNN
knn = KNeighborsClassifier(
    n_neighbors=5,
    weights='distance',  # Weight by inverse distance
    metric='euclidean'
)
knn.fit(X_train_scaled, y_train)

# Evaluate
print(f"Test Accuracy: {knn.score(X_test_scaled, y_test):.4f}")

# Cross-validation to find best k
for k in [3, 5, 7, 9]:
    knn = KNeighborsClassifier(n_neighbors=k)
    scores = cross_val_score(knn, X_train_scaled, y_train, cv=5)
    print(f"k={k}: {scores.mean():.4f} (+/- {scores.std()*2:.4f})")</code></pre>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- PCA -->
                <div class="bg-white rounded-xl shadow-lg overflow-hidden code-card transition-all duration-300">
                    <div class="p-6">
                        <div class="flex items-start justify-between mb-4">
                            <div>
                                <span class="bg-purple-100 text-purple-800 px-3 py-1 rounded-full text-sm font-medium">Dimensionality Reduction</span>
                                <span class="bg-green-100 text-green-800 px-3 py-1 rounded-full text-sm font-medium ml-2">Free</span>
                                <h3 class="text-2xl font-bold mt-2">Principal Component Analysis (PCA)</h3>
                                <p class="text-gray-600">Linear dimensionality reduction using SVD</p>
                            </div>
                        </div>

                        <button onclick="toggleContent('pca')" class="w-full bg-gradient-to-r from-purple-500 to-pink-500 text-white px-6 py-3 rounded-lg font-semibold hover:shadow-lg transition mb-4">
                            <i class="fas fa-eye mr-2"></i>View Implementation
                        </button>

                        <div id="pca" class="collapsible-content">
                            <div class="bg-purple-50 rounded-lg p-4 mb-4">
                                <h4 class="font-bold text-purple-800 mb-2"><i class="fas fa-lightbulb mr-2"></i>Key Concepts</h4>
                                <ul class="text-sm text-gray-700 space-y-1">
                                    <li><strong>Goal:</strong> Find directions (principal components) of maximum variance</li>
                                    <li><strong>Steps:</strong> Center data → Compute covariance → Eigendecomposition → Project</li>
                                    <li><strong>Explained Variance:</strong> eigenvalue_i / sum(eigenvalues)</li>
                                    <li><strong>Time Complexity:</strong> O(min(n*d², n²*d)) using SVD</li>
                                </ul>
                            </div>

                            <div class="mb-4">
                                <h4 class="font-bold text-gray-800 mb-2"><i class="fab fa-python mr-2"></i>From Scratch (NumPy only)</h4>
                                <pre class="rounded-lg"><code class="language-python">import numpy as np

class PCAFromScratch:
    def __init__(self, n_components):
        self.n_components = n_components
        self.components = None  # Principal components (eigenvectors)
        self.mean = None
        self.explained_variance_ratio = None

    def fit(self, X):
        """Fit PCA on training data"""
        X = np.array(X)

        # Step 1: Center the data (subtract mean)
        self.mean = np.mean(X, axis=0)
        X_centered = X - self.mean

        # Step 2: Compute covariance matrix
        # Cov = X^T * X / (n-1)
        n_samples = X.shape[0]
        cov_matrix = np.dot(X_centered.T, X_centered) / (n_samples - 1)

        # Step 3: Eigendecomposition
        eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)

        # Step 4: Sort eigenvectors by eigenvalues (descending)
        idx = np.argsort(eigenvalues)[::-1]
        eigenvalues = eigenvalues[idx]
        eigenvectors = eigenvectors[:, idx]

        # Step 5: Select top n_components
        self.components = eigenvectors[:, :self.n_components].T

        # Calculate explained variance ratio
        total_var = np.sum(eigenvalues)
        self.explained_variance_ratio = eigenvalues[:self.n_components] / total_var

        return self

    def transform(self, X):
        """Project data onto principal components"""
        X = np.array(X)
        X_centered = X - self.mean
        return np.dot(X_centered, self.components.T)

    def fit_transform(self, X):
        """Fit and transform in one step"""
        self.fit(X)
        return self.transform(X)

    def inverse_transform(self, X_transformed):
        """Reconstruct original data (with information loss)"""
        return np.dot(X_transformed, self.components) + self.mean

# Usage Example
if __name__ == "__main__":
    from sklearn.datasets import load_iris

    iris = load_iris()
    X = iris.data  # 4 features

    # Reduce to 2 dimensions
    pca = PCAFromScratch(n_components=2)
    X_reduced = pca.fit_transform(X)

    print(f"Original shape: {X.shape}")
    print(f"Reduced shape: {X_reduced.shape}")
    print(f"Explained variance ratio: {pca.explained_variance_ratio}")
    print(f"Total variance explained: {sum(pca.explained_variance_ratio):.4f}")</code></pre>
                            </div>

                            <div>
                                <h4 class="font-bold text-gray-800 mb-2"><i class="fas fa-box mr-2"></i>With Scikit-Learn</h4>
                                <pre class="rounded-lg"><code class="language-python">from sklearn.decomposition import PCA
from sklearn.datasets import load_iris
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Load data
iris = load_iris()
X = iris.data
y = iris.target

# IMPORTANT: Scale data before PCA!
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Fit PCA
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

# Analysis
print(f"Explained variance ratio: {pca.explained_variance_ratio_}")
print(f"Total variance explained: {sum(pca.explained_variance_ratio_):.4f}")
print(f"Component shape: {pca.components_.shape}")

# Find optimal number of components (95% variance)
pca_full = PCA()
pca_full.fit(X_scaled)
cumsum = np.cumsum(pca_full.explained_variance_ratio_)
n_components_95 = np.argmax(cumsum >= 0.95) + 1
print(f"Components needed for 95% variance: {n_components_95}")</code></pre>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- DNN (Neural Network) -->
                <div class="bg-white rounded-xl shadow-lg overflow-hidden code-card transition-all duration-300">
                    <div class="p-6">
                        <div class="flex items-start justify-between mb-4">
                            <div>
                                <span class="bg-orange-100 text-orange-800 px-3 py-1 rounded-full text-sm font-medium">Deep Learning</span>
                                <span class="bg-green-100 text-green-800 px-3 py-1 rounded-full text-sm font-medium ml-2">Free</span>
                                <h3 class="text-2xl font-bold mt-2">Deep Neural Network (DNN)</h3>
                                <p class="text-gray-600">Multi-layer perceptron with backpropagation</p>
                            </div>
                        </div>

                        <button onclick="toggleContent('dnn')" class="w-full bg-gradient-to-r from-orange-500 to-red-500 text-white px-6 py-3 rounded-lg font-semibold hover:shadow-lg transition mb-4">
                            <i class="fas fa-eye mr-2"></i>View Implementation
                        </button>

                        <div id="dnn" class="collapsible-content">
                            <div class="bg-orange-50 rounded-lg p-4 mb-4">
                                <h4 class="font-bold text-orange-800 mb-2"><i class="fas fa-lightbulb mr-2"></i>Key Concepts</h4>
                                <ul class="text-sm text-gray-700 space-y-1">
                                    <li><strong>Forward Pass:</strong> z = Wx + b, a = activation(z)</li>
                                    <li><strong>Backward Pass:</strong> Compute gradients via chain rule</li>
                                    <li><strong>Weight Update:</strong> W = W - lr * dL/dW</li>
                                    <li><strong>Key:</strong> Xavier/He initialization, batch normalization, dropout</li>
                                </ul>
                            </div>

                            <div class="mb-4">
                                <h4 class="font-bold text-gray-800 mb-2"><i class="fab fa-python mr-2"></i>From Scratch (NumPy only)</h4>
                                <pre class="rounded-lg"><code class="language-python">import numpy as np

class NeuralNetworkFromScratch:
    def __init__(self, layer_sizes, learning_rate=0.01):
        """
        layer_sizes: list like [input_dim, hidden1, hidden2, ..., output_dim]
        """
        self.layer_sizes = layer_sizes
        self.lr = learning_rate
        self.weights = []
        self.biases = []

        # Xavier initialization
        for i in range(len(layer_sizes) - 1):
            w = np.random.randn(layer_sizes[i], layer_sizes[i+1]) * np.sqrt(2.0 / layer_sizes[i])
            b = np.zeros((1, layer_sizes[i+1]))
            self.weights.append(w)
            self.biases.append(b)

    def _relu(self, z):
        return np.maximum(0, z)

    def _relu_derivative(self, z):
        return (z > 0).astype(float)

    def _softmax(self, z):
        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))
        return exp_z / np.sum(exp_z, axis=1, keepdims=True)

    def _cross_entropy_loss(self, y_pred, y_true):
        n_samples = y_true.shape[0]
        # Clip to prevent log(0)
        y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)
        loss = -np.sum(y_true * np.log(y_pred)) / n_samples
        return loss

    def forward(self, X):
        """Forward pass - store activations for backprop"""
        self.activations = [X]
        self.z_values = []

        current = X
        for i in range(len(self.weights) - 1):
            z = np.dot(current, self.weights[i]) + self.biases[i]
            self.z_values.append(z)
            current = self._relu(z)
            self.activations.append(current)

        # Output layer (softmax for classification)
        z = np.dot(current, self.weights[-1]) + self.biases[-1]
        self.z_values.append(z)
        output = self._softmax(z)
        self.activations.append(output)

        return output

    def backward(self, y_true):
        """Backpropagation"""
        n_samples = y_true.shape[0]
        n_layers = len(self.weights)

        # Output layer gradient
        delta = self.activations[-1] - y_true  # softmax + cross-entropy derivative

        gradients_w = []
        gradients_b = []

        # Backpropagate through layers
        for i in range(n_layers - 1, -1, -1):
            grad_w = np.dot(self.activations[i].T, delta) / n_samples
            grad_b = np.mean(delta, axis=0, keepdims=True)

            gradients_w.insert(0, grad_w)
            gradients_b.insert(0, grad_b)

            if i > 0:
                delta = np.dot(delta, self.weights[i].T) * self._relu_derivative(self.z_values[i-1])

        # Update weights
        for i in range(len(self.weights)):
            self.weights[i] -= self.lr * gradients_w[i]
            self.biases[i] -= self.lr * gradients_b[i]

    def fit(self, X, y, epochs=100, verbose=True):
        """Train the network"""
        # One-hot encode labels
        n_classes = len(np.unique(y))
        y_onehot = np.eye(n_classes)[y]

        for epoch in range(epochs):
            # Forward pass
            y_pred = self.forward(X)

            # Compute loss
            loss = self._cross_entropy_loss(y_pred, y_onehot)

            # Backward pass
            self.backward(y_onehot)

            if verbose and epoch % 10 == 0:
                acc = self.score(X, y)
                print(f"Epoch {epoch}: Loss={loss:.4f}, Accuracy={acc:.4f}")

    def predict(self, X):
        output = self.forward(X)
        return np.argmax(output, axis=1)

    def score(self, X, y):
        predictions = self.predict(X)
        return np.mean(predictions == y)

# Usage
if __name__ == "__main__":
    from sklearn.datasets import load_iris
    from sklearn.model_selection import train_test_split
    from sklearn.preprocessing import StandardScaler

    iris = load_iris()
    X_train, X_test, y_train, y_test = train_test_split(
        iris.data, iris.target, test_size=0.2, random_state=42
    )

    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    # Network: 4 inputs -> 16 hidden -> 8 hidden -> 3 outputs
    nn = NeuralNetworkFromScratch([4, 16, 8, 3], learning_rate=0.1)
    nn.fit(X_train, y_train, epochs=100)
    print(f"\nTest Accuracy: {nn.score(X_test, y_test):.4f}")</code></pre>
                            </div>

                            <div>
                                <h4 class="font-bold text-gray-800 mb-2"><i class="fas fa-box mr-2"></i>With PyTorch</h4>
                                <pre class="rounded-lg"><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Define model
class DNN(nn.Module):
    def __init__(self, input_dim, hidden_dims, output_dim):
        super().__init__()
        layers = []
        prev_dim = input_dim

        for hidden_dim in hidden_dims:
            layers.extend([
                nn.Linear(prev_dim, hidden_dim),
                nn.ReLU(),
                nn.BatchNorm1d(hidden_dim),
                nn.Dropout(0.2)
            ])
            prev_dim = hidden_dim

        layers.append(nn.Linear(prev_dim, output_dim))
        self.network = nn.Sequential(*layers)

    def forward(self, x):
        return self.network(x)

# Prepare data
iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(
    iris.data, iris.target, test_size=0.2, random_state=42
)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

X_train = torch.FloatTensor(X_train)
X_test = torch.FloatTensor(X_test)
y_train = torch.LongTensor(y_train)
y_test = torch.LongTensor(y_test)

# Train
model = DNN(input_dim=4, hidden_dims=[16, 8], output_dim=3)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.01)

for epoch in range(100):
    model.train()
    optimizer.zero_grad()
    outputs = model(X_train)
    loss = criterion(outputs, y_train)
    loss.backward()
    optimizer.step()

# Evaluate
model.eval()
with torch.no_grad():
    outputs = model(X_test)
    _, predicted = torch.max(outputs, 1)
    accuracy = (predicted == y_test).float().mean()
    print(f"Test Accuracy: {accuracy:.4f}")</code></pre>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Premium Section -->
    <section class="py-12 bg-gradient-to-br from-purple-50 to-pink-50">
        <div class="max-w-7xl mx-auto px-4">
            <h2 class="text-2xl font-bold mb-6 flex items-center">
                <i class="fas fa-lock text-purple-500 mr-3"></i>Premium ML Coding (Unlock with Mentorship)
            </h2>

            <div class="relative">
                <div class="grid md:grid-cols-3 gap-6 premium-blur">
                    <div class="bg-white rounded-xl shadow p-6">
                        <span class="bg-green-100 text-green-800 px-2 py-1 rounded text-xs">Classification</span>
                        <h3 class="font-bold mt-2">Support Vector Machine (SVM)</h3>
                        <p class="text-sm text-gray-600">Kernel trick, margin maximization, soft vs hard margin...</p>
                    </div>
                    <div class="bg-white rounded-xl shadow p-6">
                        <span class="bg-red-100 text-red-800 px-2 py-1 rounded text-xs">Computer Vision</span>
                        <h3 class="font-bold mt-2">Convolutional Neural Network (CNN)</h3>
                        <p class="text-sm text-gray-600">Conv layers, pooling, feature maps, backprop through conv...</p>
                    </div>
                    <div class="bg-white rounded-xl shadow p-6">
                        <span class="bg-cyan-100 text-cyan-800 px-2 py-1 rounded text-xs">Sequences</span>
                        <h3 class="font-bold mt-2">Recurrent Neural Network (RNN/LSTM)</h3>
                        <p class="text-sm text-gray-600">Hidden states, BPTT, vanishing gradients, LSTM gates...</p>
                    </div>
                </div>

                <div class="absolute inset-0 flex items-center justify-center">
                    <div class="bg-white rounded-2xl shadow-2xl p-8 text-center max-w-md">
                        <i class="fas fa-crown text-5xl text-yellow-500 mb-4"></i>
                        <h3 class="text-2xl font-bold mb-2">Unlock All ML Coding</h3>
                        <p class="text-gray-600 mb-4">SVM, CNN, RNN/LSTM implementations with full explanations</p>
                        <a href="https://mentorcruise.com/mentor/AminGhaderi/" target="_blank"
                           class="bg-gradient-to-r from-purple-600 to-pink-600 text-white px-8 py-3 rounded-full font-bold hover:shadow-lg transition inline-block">
                            <i class="fas fa-user-tie mr-2"></i>Book Mentorship
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="bg-gray-900 text-white py-8">
        <div class="max-w-7xl mx-auto px-4 text-center">
            <p class="mb-4">Want to master ML coding interviews? <a href="https://mentorcruise.com/mentor/AminGhaderi/" target="_blank" class="text-pink-400 hover:underline">Book a session</a></p>
            <p class="text-gray-500">&copy; 2025 MLInterviewPro</p>
        </div>
    </footer>

    <script>
        function toggleContent(id) {
            const content = document.getElementById(id);
            content.classList.toggle('open');
        }
        hljs.highlightAll();
    </script>
</body>
</html>
